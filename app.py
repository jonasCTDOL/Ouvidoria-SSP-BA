import streamlit as st
import mysql.connector
import pandas as pd
import requests # Usado para fazer chamadas √† API do Hugging Face
import json

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="An√°lise de Colabora√ß√µes com IA",
    page_icon="üí°"
)

# --- FUN√á√ïES DE L√ìGICA ---

@st.cache_data(ttl=3600)
def fetch_data_from_db():
    """Conecta ao banco de dados MySQL usando os segredos e busca os dados."""
    try:
        conn = mysql.connector.connect(**st.secrets["mysql"])
        query = "SELECT * FROM colaboracoes WHERE created_at >= NOW() - INTERVAL 90 DAY;"
        df = pd.read_sql(query, conn)
        conn.close()
        return df
    except Exception as e:
        st.error(f"Ocorreu um erro ao conectar ou buscar dados: {e}")
        return None

def build_prompt(user_question, df):
    """Monta o prompt para um modelo de instru√ß√£o a partir da pergunta e dos dados."""
    data_csv = df.to_csv(index=False)
    # Modelos de instru√ß√£o funcionam melhor com um formato claro de tarefa
    prompt = f"""
[INST] Voc√™ √© um assistente de an√°lise de dados. Sua tarefa √© analisar os dados em formato CSV abaixo e responder √† pergunta do usu√°rio de forma clara e concisa. Baseie sua resposta apenas nos dados fornecidos.

--- DADOS ---
{data_csv}

--- PERGUNTA ---
{user_question} [/INST]
"""
    return prompt

def generate_insight_huggingface(prompt):
    """Envia o prompt para a API do Hugging Face e retorna a resposta."""
    # CORRE√á√ÉO: Trocado para um modelo alternativo e robusto da MistralAI.
    model_url = "https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1"
    
    try:
        api_token = st.secrets["huggingface_api"]["token"]
        headers = {"Authorization": f"Bearer {api_token}"}
        
        payload = {"inputs": prompt}
        
        response = requests.post(model_url, headers=headers, json=payload)
        
        # Verifica se a resposta foi bem-sucedida
        if response.status_code == 200:
            # A resposta da API do Hugging Face vem numa lista
            result = response.json()
            # Pega o texto gerado do primeiro (e √∫nico) resultado
            generated_text = result[0]['generated_text']
            # O modelo repete o prompt na resposta, ent√£o removemos o prompt original
            # para obter apenas a resposta da IA.
            answer = generated_text.replace(prompt, "").strip()
            return answer
        else:
            st.error(f"Erro ao chamar a API do Hugging Face: {response.status_code} - {response.text}")
            return None

    except Exception as e:
        st.error(f"Ocorreu uma exce√ß√£o ao chamar a API do Hugging Face: {e}")
        return None

# --- INTERFACE DO USU√ÅRIO (UI) ---

st.title("üí° Assistente de An√°lise de Colabora√ß√µes")
st.markdown("Fa√ßa uma pergunta sobre as colabora√ß√µes dos √∫ltimos 90 dias e a IA ir√° gerar um insight para voc√™.")
st.info("‚ÑπÔ∏è Esta demonstra√ß√£o usa um modelo da comunidade Hugging Face. A primeira gera√ß√£o pode demorar um pouco mais.")

default_question = "Qual cidade teve mais colabora√ß√µes e qual o tipo de colabora√ß√£o mais comum ('denuncia', 'sugestao', etc.)?"
user_question = st.text_area("Sua pergunta:", value=default_question, height=100)

if st.button("Gerar Insight"):
    if not user_question:
        st.warning("Por favor, digite uma pergunta para an√°lise.")
    else:
        with st.spinner("Conectando ao banco de dados..."):
            dados_df = fetch_data_from_db()

        if dados_df is not None:
            if dados_df.empty:
                st.info("Nenhum registro encontrado nos √∫ltimos 90 dias.")
            else:
                st.success(f"Dados carregados! {len(dados_df)} registros encontrados.")
                
                with st.spinner("A IA do Hugging Face est√° a processar... (pode demorar um pouco na primeira vez)"):
                    prompt = build_prompt(user_question, dados_df)
                    insight = generate_insight_huggingface(prompt)

                if insight:
                    st.subheader("An√°lise Gerada pela IA:")
                    st.markdown(insight)

